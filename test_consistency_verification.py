"""
ä¸€è‡´æ€§é©—è­‰æ¸¬è©¦è…³æœ¬

æª¢æŸ¥æ¨¡æ“¬æ•¸æ“šç”Ÿæˆåœ¨ä¸åŒæƒ…æ³ä¸‹çš„ä¸€è‡´æ€§å’Œç©©å®šæ€§
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Tuple
from src.ui.results_display import ResultsDisplayManager
from src.utils.logger import get_component_logger
import matplotlib.pyplot as plt

logger = get_component_logger("ConsistencyVerification")


class ConsistencyVerificationTester:
    """ä¸€è‡´æ€§é©—è­‰æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.results_manager = ResultsDisplayManager()
        self.test_results = []
        
    def run_all_consistency_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰ä¸€è‡´æ€§é©—è­‰æ¸¬è©¦"""
        logger.info("=== é–‹å§‹ä¸€è‡´æ€§é©—è­‰æ¸¬è©¦ ===")
        
        test_results = {
            'reproducibility': self.test_reproducibility(),
            'parameter_sensitivity': self.test_parameter_sensitivity(),
            'frequency_consistency': self.test_frequency_consistency(),
            'temporal_stability': self.test_temporal_stability(),
            'statistical_properties': self.test_statistical_properties()
        }
        
        # è¨ˆç®—æ•´é«”é€šéç‡
        total_tests = len(test_results)
        passed_tests = sum(1 for result in test_results.values() if result['passed'])
        
        summary = {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'pass_rate': passed_tests / total_tests,
            'test_details': test_results,
            'overall_status': 'PASS' if passed_tests == total_tests else 'PARTIAL_PASS'
        }
        
        logger.info(f"ä¸€è‡´æ€§é©—è­‰æ¸¬è©¦å®Œæˆï¼š{passed_tests}/{total_tests} é€šé")
        return summary
    
    def test_reproducibility(self) -> Dict[str, Any]:
        """æ¸¬è©¦å¯é‡ç¾æ€§ - ç›¸åŒåƒæ•¸å¤šæ¬¡é‹è¡Œçš„ä¸€è‡´æ€§"""
        logger.info("æ¸¬è©¦å¯é‡ç¾æ€§...")
        
        try:
            # æ¨™æº–æ¸¬è©¦åƒæ•¸
            parameters = {
                "investment_amount": 10000,
                "investment_periods": 10,
                "investment_frequency": "annually",
                "start_date": datetime(2020, 1, 1),
                "stock_ratio": 60,
                "bond_ratio": 40,
                "rebalance_threshold_upper": 70,
                "rebalance_threshold_lower": 50
            }
            
            # é‹è¡Œå¤šæ¬¡æ¸¬è©¦
            runs = []
            for i in range(5):
                market_data = self.results_manager._generate_fallback_data(parameters)
                runs.append(market_data)
            
            # åˆ†æä¸€è‡´æ€§
            consistency_scores = []
            
            for i in range(1, len(runs)):
                # æ¯”è¼ƒè‚¡ç¥¨åƒ¹æ ¼è»Œè·¡
                price_correlation = np.corrcoef(
                    runs[0]['SPY_Price_End'].values,
                    runs[i]['SPY_Price_End'].values
                )[0, 1]
                
                # æ¯”è¼ƒæ®–åˆ©ç‡è»Œè·¡
                yield_correlation = np.corrcoef(
                    runs[0]['Bond_Yield_End'].values,
                    runs[i]['Bond_Yield_End'].values
                )[0, 1]
                
                # åƒ¹æ ¼ç¯„åœä¸€è‡´æ€§
                price_range_similarity = self._calculate_range_similarity(
                    runs[0]['SPY_Price_End'], runs[i]['SPY_Price_End']
                )
                
                run_score = np.mean([
                    1 - abs(price_correlation),  # ç›¸é—œæ€§æ‡‰è©²ä½ï¼ˆå› ç‚ºæ˜¯éš¨æ©Ÿç”Ÿæˆï¼‰
                    1 - abs(yield_correlation),
                    price_range_similarity
                ])
                consistency_scores.append(run_score)
            
            avg_consistency = np.mean(consistency_scores)
            
            # è©•åˆ†æ¨™æº–ï¼šå¹³å‡ä¸€è‡´æ€§ > 0.3 ç‚ºåˆæ ¼ï¼ˆå…è¨±éš¨æ©Ÿæ€§ä½†çµæ§‹ä¸€è‡´ï¼‰
            passed = avg_consistency > 0.3
            
            return {
                'test_name': 'reproducibility',
                'passed': passed,
                'score': avg_consistency,
                'message': f'å¯é‡ç¾æ€§æ¸¬è©¦ï¼šå¹³å‡ä¸€è‡´æ€§{avg_consistency:.3f}'
            }
            
        except Exception as e:
            return {
                'test_name': 'reproducibility',
                'passed': False,
                'score': 0.0,
                'message': f'å¯é‡ç¾æ€§æ¸¬è©¦å¤±æ•—ï¼š{e}'
            }
    
    def test_parameter_sensitivity(self) -> Dict[str, Any]:
        """æ¸¬è©¦åƒæ•¸æ•æ„Ÿæ€§ - åƒæ•¸å¾®èª¿å°çµæœçš„å½±éŸ¿"""
        logger.info("æ¸¬è©¦åƒæ•¸æ•æ„Ÿæ€§...")
        
        try:
            # åŸºæº–åƒæ•¸
            base_parameters = {
                "investment_amount": 10000,
                "investment_periods": 10,
                "investment_frequency": "annually", 
                "start_date": datetime(2020, 1, 1),
                "stock_ratio": 60,
                "bond_ratio": 40,
                "rebalance_threshold_upper": 70,
                "rebalance_threshold_lower": 50
            }
            
            # ç²å–åŸºæº–çµæœ
            base_data = self.results_manager._generate_fallback_data(base_parameters)
            
            # æ¸¬è©¦å¾®èª¿åƒæ•¸çš„å½±éŸ¿
            sensitivity_tests = [
                {"investment_amount": 10100},  # +1%
                {"investment_periods": 11},    # +10%
                {"stock_ratio": 61, "bond_ratio": 39},  # +1%è‚¡ç¥¨æ¯”ä¾‹
                {"rebalance_threshold_upper": 71, "rebalance_threshold_lower": 49}  # å¾®èª¿é–¾å€¼
            ]
            
            sensitivity_scores = []
            
            for test_params in sensitivity_tests:
                modified_params = base_parameters.copy()
                modified_params.update(test_params)
                
                try:
                    modified_data = self.results_manager._generate_fallback_data(modified_params)
                    
                    if len(modified_data) == len(base_data):
                        # è¨ˆç®—åƒ¹æ ¼è»Œè·¡ç›¸ä¼¼æ€§
                        price_similarity = self._calculate_trajectory_similarity(
                            base_data['SPY_Price_End'].values,
                            modified_data['SPY_Price_End'].values
                        )
                        
                        # å¾®èª¿æ‡‰è©²ç”¢ç”Ÿç›¸ä¼¼ä½†éå®Œå…¨ç›¸åŒçš„çµæœ
                        # ç›¸ä¼¼æ€§åœ¨0.7-0.95ä¹‹é–“ç‚ºç†æƒ³
                        if 0.7 <= price_similarity <= 0.95:
                            sensitivity_scores.append(1.0)
                        elif price_similarity > 0.95:
                            sensitivity_scores.append(0.7)  # å¤ªç›¸ä¼¼
                        elif price_similarity < 0.7:
                            sensitivity_scores.append(0.5)  # å¤ªä¸åŒ
                        else:
                            sensitivity_scores.append(0.0)
                    else:
                        sensitivity_scores.append(0.0)
                        
                except Exception as e:
                    logger.warning(f"æ•æ„Ÿæ€§æ¸¬è©¦å¤±æ•—ï¼š{test_params}, {e}")
                    sensitivity_scores.append(0.0)
            
            avg_sensitivity = np.mean(sensitivity_scores)
            passed = avg_sensitivity > 0.6
            
            return {
                'test_name': 'parameter_sensitivity',
                'passed': passed,
                'score': avg_sensitivity,
                'message': f'åƒæ•¸æ•æ„Ÿæ€§æ¸¬è©¦ï¼šå¹³å‡è©•åˆ†{avg_sensitivity:.3f}'
            }
            
        except Exception as e:
            return {
                'test_name': 'parameter_sensitivity',
                'passed': False,
                'score': 0.0,
                'message': f'åƒæ•¸æ•æ„Ÿæ€§æ¸¬è©¦å¤±æ•—ï¼š{e}'
            }
    
    def test_frequency_consistency(self) -> Dict[str, Any]:
        """æ¸¬è©¦è·¨é »ç‡è¨ˆç®—ä¸€è‡´æ€§"""
        logger.info("æ¸¬è©¦è·¨é »ç‡è¨ˆç®—ä¸€è‡´æ€§...")
        
        try:
            base_params = {
                "investment_amount": 12000,  # å¯è¢«12æ•´é™¤ï¼Œä¾¿æ–¼æœˆåº¦æ¯”è¼ƒ
                "investment_periods": 2,     # 2å¹´
                "start_date": datetime(2020, 1, 1),
                "stock_ratio": 60,
                "bond_ratio": 40,
                "rebalance_threshold_upper": 70,
                "rebalance_threshold_lower": 50
            }
            
            # æ¸¬è©¦ä¸åŒé »ç‡
            frequencies = ["annually", "quarterly", "monthly"]
            results = {}
            
            for freq in frequencies:
                params = base_params.copy()
                params["investment_frequency"] = freq
                
                data = self.results_manager._generate_fallback_data(params)
                results[freq] = data
            
            # é©—è­‰æœŸæ•¸æ­£ç¢ºæ€§
            expected_periods = {"annually": 2, "quarterly": 8, "monthly": 24}
            period_check = all(
                len(results[freq]) == expected_periods[freq] 
                for freq in frequencies
            )
            
            # æª¢æŸ¥æ•¸æ“šå“è³ªä¸€è‡´æ€§
            quality_scores = []
            for freq in frequencies:
                data = results[freq]
                if not data.empty:
                    # è¨ˆç®—å¹³å‡æœŸé–“æ”¶ç›Šç‡
                    returns = (data['SPY_Price_End'] - data['SPY_Price_Origin']) / data['SPY_Price_Origin']
                    avg_return = returns.mean()
                    
                    # å¹´åŒ–æ”¶ç›Šç‡æ‡‰è©²ç›¸è¿‘ï¼ˆè€ƒæ…®è¤‡åˆ©æ•ˆæ‡‰ï¼‰
                    periods_per_year = expected_periods[freq] / 2  # 2å¹´
                    annualized_return = (1 + avg_return) ** periods_per_year - 1
                    
                    # å¹´åŒ–æ”¶ç›Šç‡æ‡‰è©²åœ¨åˆç†ç¯„åœå…§ï¼ˆç´„6%å¹´åŒ–ï¼Œå°æ‡‰1.5%æ¯æœŸï¼‰
                    if 0.04 <= annualized_return <= 0.12:  # 4%-12%å¹´åŒ–
                        quality_scores.append(1.0)
                    else:
                        quality_scores.append(0.5)
                else:
                    quality_scores.append(0.0)
            
            avg_quality = np.mean(quality_scores)
            passed = period_check and avg_quality > 0.7
            
            return {
                'test_name': 'frequency_consistency',
                'passed': passed,
                'score': avg_quality,
                'message': f'é »ç‡ä¸€è‡´æ€§æ¸¬è©¦ï¼šæœŸæ•¸æª¢æŸ¥{period_check}ï¼Œå“è³ªè©•åˆ†{avg_quality:.3f}'
            }
            
        except Exception as e:
            return {
                'test_name': 'frequency_consistency',
                'passed': False,
                'score': 0.0,
                'message': f'é »ç‡ä¸€è‡´æ€§æ¸¬è©¦å¤±æ•—ï¼š{e}'
            }
    
    def test_temporal_stability(self) -> Dict[str, Any]:
        """æ¸¬è©¦æ™‚é–“ç©©å®šæ€§ - ä¸åŒèµ·å§‹æ—¥æœŸçš„ç©©å®šæ€§"""
        logger.info("æ¸¬è©¦æ™‚é–“ç©©å®šæ€§...")
        
        try:
            base_params = {
                "investment_amount": 10000,
                "investment_periods": 5,
                "investment_frequency": "annually",
                "stock_ratio": 60,
                "bond_ratio": 40,
                "rebalance_threshold_upper": 70,
                "rebalance_threshold_lower": 50
            }
            
            # æ¸¬è©¦ä¸åŒèµ·å§‹æ—¥æœŸ
            start_dates = [
                datetime(2020, 1, 1),
                datetime(2021, 6, 15),
                datetime(2022, 12, 31),
                datetime(2015, 3, 10)
            ]
            
            results = []
            for start_date in start_dates:
                params = base_params.copy()
                params["start_date"] = start_date
                
                data = self.results_manager._generate_fallback_data(params)
                if not data.empty:
                    # è¨ˆç®—çµ±è¨ˆç‰¹å¾µ
                    stats = {
                        'mean_return': ((data['SPY_Price_End'] - data['SPY_Price_Origin']) / data['SPY_Price_Origin']).mean(),
                        'volatility': ((data['SPY_Price_End'] - data['SPY_Price_Origin']) / data['SPY_Price_Origin']).std(),
                        'yield_stability': data['Bond_Yield_End'].std()
                    }
                    results.append(stats)
            
            if len(results) >= 3:
                # åˆ†æçµ±è¨ˆç‰¹å¾µçš„ç©©å®šæ€§
                mean_returns = [r['mean_return'] for r in results]
                volatilities = [r['volatility'] for r in results]
                yield_stabilities = [r['yield_stability'] for r in results]
                
                # è¨ˆç®—è®Šç•°ä¿‚æ•¸ï¼ˆæ¨™æº–å·®/å¹³å‡å€¼ï¼‰
                return_cv = np.std(mean_returns) / np.mean(mean_returns) if np.mean(mean_returns) != 0 else 1
                volatility_cv = np.std(volatilities) / np.mean(volatilities) if np.mean(volatilities) != 0 else 1
                yield_cv = np.std(yield_stabilities) / np.mean(yield_stabilities) if np.mean(yield_stabilities) != 0 else 1
                
                # è®Šç•°ä¿‚æ•¸æ‡‰è©²ç›¸å°è¼ƒå°ï¼ˆ< 0.5ï¼‰è¡¨ç¤ºç©©å®š
                stability_score = np.mean([
                    1 - min(return_cv, 1.0),
                    1 - min(volatility_cv, 1.0),
                    1 - min(yield_cv, 1.0)
                ])
                
                passed = stability_score > 0.5
                
                return {
                    'test_name': 'temporal_stability',
                    'passed': passed,
                    'score': stability_score,
                    'message': f'æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ï¼šç©©å®šæ€§è©•åˆ†{stability_score:.3f}'
                }
            else:
                return {
                    'test_name': 'temporal_stability',
                    'passed': False,
                    'score': 0.0,
                    'message': 'æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ï¼šæœ‰æ•ˆçµæœä¸è¶³'
                }
                
        except Exception as e:
            return {
                'test_name': 'temporal_stability',
                'passed': False,
                'score': 0.0,
                'message': f'æ™‚é–“ç©©å®šæ€§æ¸¬è©¦å¤±æ•—ï¼š{e}'
            }
    
    def test_statistical_properties(self) -> Dict[str, Any]:
        """æ¸¬è©¦çµ±è¨ˆç‰¹æ€§çš„åˆç†æ€§"""
        logger.info("æ¸¬è©¦çµ±è¨ˆç‰¹æ€§...")
        
        try:
            parameters = {
                "investment_amount": 10000,
                "investment_periods": 20,
                "investment_frequency": "annually",
                "start_date": datetime(2000, 1, 1),
                "stock_ratio": 60,
                "bond_ratio": 40,
                "rebalance_threshold_upper": 70,
                "rebalance_threshold_lower": 50
            }
            
            data = self.results_manager._generate_fallback_data(parameters)
            
            if data.empty:
                return {
                    'test_name': 'statistical_properties',
                    'passed': False,
                    'score': 0.0,
                    'message': 'çµ±è¨ˆç‰¹æ€§æ¸¬è©¦ï¼šæ•¸æ“šç‚ºç©º'
                }
            
            # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
            returns = (data['SPY_Price_End'] - data['SPY_Price_Origin']) / data['SPY_Price_Origin']
            
            stats = {
                'mean_return': returns.mean(),
                'volatility': returns.std(),
                'skewness': returns.skew(),
                'kurtosis': returns.kurtosis(),
                'min_return': returns.min(),
                'max_return': returns.max()
            }
            
            # è©•ä¼°çµ±è¨ˆåˆç†æ€§
            checks = {
                'mean_reasonable': 0.005 <= stats['mean_return'] <= 0.03,  # 0.5%-3%æœŸé–“æ”¶ç›Šç‡
                'volatility_reasonable': 0.02 <= stats['volatility'] <= 0.15,  # 2%-15%æ³¢å‹•ç‡
                'skewness_reasonable': -2 <= stats['skewness'] <= 2,  # ååº¦åˆç†ç¯„åœ
                'kurtosis_reasonable': -2 <= stats['kurtosis'] <= 5,  # å³°åº¦åˆç†ç¯„åœ
                'extreme_reasonable': -0.15 <= stats['min_return'] and stats['max_return'] <= 0.15  # æ¥µå€¼åˆç†
            }
            
            passed_checks = sum(checks.values())
            total_checks = len(checks)
            score = passed_checks / total_checks
            
            passed = score > 0.7
            
            return {
                'test_name': 'statistical_properties',
                'passed': passed,
                'score': score,
                'message': f'çµ±è¨ˆç‰¹æ€§æ¸¬è©¦ï¼š{passed_checks}/{total_checks} æª¢æŸ¥é€šé',
                'details': stats
            }
            
        except Exception as e:
            return {
                'test_name': 'statistical_properties',
                'passed': False,
                'score': 0.0,
                'message': f'çµ±è¨ˆç‰¹æ€§æ¸¬è©¦å¤±æ•—ï¼š{e}'
            }
    
    def _calculate_range_similarity(self, series1: pd.Series, series2: pd.Series) -> float:
        """è¨ˆç®—å…©å€‹åºåˆ—çš„ç¯„åœç›¸ä¼¼æ€§"""
        try:
            range1 = series1.max() - series1.min()
            range2 = series2.max() - series2.min()
            
            if range1 == 0 and range2 == 0:
                return 1.0
            elif range1 == 0 or range2 == 0:
                return 0.0
            else:
                ratio = min(range1, range2) / max(range1, range2)
                return ratio
        except:
            return 0.0
    
    def _calculate_trajectory_similarity(self, arr1: np.ndarray, arr2: np.ndarray) -> float:
        """è¨ˆç®—å…©å€‹è»Œè·¡çš„ç›¸ä¼¼æ€§"""
        try:
            if len(arr1) != len(arr2):
                return 0.0
            
            # æ­£è¦åŒ–
            arr1_norm = (arr1 - arr1.min()) / (arr1.max() - arr1.min()) if arr1.max() != arr1.min() else np.zeros_like(arr1)
            arr2_norm = (arr2 - arr2.min()) / (arr2.max() - arr2.min()) if arr2.max() != arr2.min() else np.zeros_like(arr2)
            
            # è¨ˆç®—ç›¸é—œä¿‚æ•¸
            correlation = np.corrcoef(arr1_norm, arr2_norm)[0, 1]
            
            # è™•ç†NaNæƒ…æ³
            if np.isnan(correlation):
                correlation = 0.0
            
            return abs(correlation)
        except:
            return 0.0


def main():
    """ä¸»å‡½æ•¸"""
    tester = ConsistencyVerificationTester()
    summary = tester.run_all_consistency_tests()
    
    print("\n" + "="*60)
    print("ä¸€è‡´æ€§é©—è­‰æ¸¬è©¦å ±å‘Š")
    print("="*60)
    
    print(f"\nğŸ“Š æ•´é«”çµæœï¼š{summary['overall_status']}")
    print(f"é€šéç‡ï¼š{summary['pass_rate']:.1%} ({summary['passed_tests']}/{summary['total_tests']})")
    
    print("\nğŸ“‹ è©³ç´°çµæœï¼š")
    for test_name, result in summary['test_details'].items():
        status = "âœ…" if result['passed'] else "âŒ"
        score = result.get('score', 0.0)
        print(f"  {status} {test_name}: {result['message']} (è©•åˆ†: {score:.3f})")
        
        # é¡¯ç¤ºè©³ç´°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'details' in result:
            details = result['details']
            print(f"      è©³æƒ…: å¹³å‡æ”¶ç›Š={details['mean_return']:.3f}, æ³¢å‹•ç‡={details['volatility']:.3f}")
    
    # ä¿å­˜çµæœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"consistency_verification_report_{timestamp}.json"
    
    try:
        import json
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ æ¸¬è©¦å ±å‘Šå·²ä¿å­˜è‡³ï¼š{filename}")
    except Exception as e:
        logger.error(f"ä¿å­˜å ±å‘Šå¤±æ•—ï¼š{e}")
    
    return summary


if __name__ == "__main__":
    main() 